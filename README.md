# Awesome World Models for Manipulation [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A collection of useful papers and resources on World Models for Manipulation.

Created for the 1X World Model Challenge.

If you want to add a paper, rearrange papers, or create a new category, please [contribue](contributing.md) :^)


## Blog posts


- A Drive in the office (Comma AI) **`2024.5`** [[blog](https://blog.comma.ai/a-drive-in-the-office/)]


## Challenges

- 1X World Model Challenge: world modeling challenge for humanoid robots **`2024.8`** [[code](https://github.com/1x-technologies/1xgpt)]

## Survey

- A Survey on Vision-Language-Action Models for Embodied AI **`arXiv 2024.5`** [[paper](https://arxiv.org/abs/2405.14093)]


## World Models for Manipulation

- UniSim: Learning Interactive Real-World Simulators **`ICLR 2024`** [[paper](https://openreview.net/pdf?id=sFyTZEqmUY)] [[website](https://universal-simulator.github.io/unisim/)]
- RoboDreamer: Learning Compositional World Models for Robot Imagination **`ICML 2024`** [[paper](https://arxiv.org/pdf/2404.12377)] [[code](https://github.com/rainbow979/robodreamer)] [[website](https://robovideo.github.io)]
- IRASim: Learning Interactive Real-Robot Action Simulators **`arXiv 2024.6`** [[paper](https://arxiv.org/pdf/22406.14540)] [[code](https://github.com/bytedance/IRASim)] [[website](https://gen-irasim.github.io)]
- Structured World Models from Human Videos **`RSS 2023`** [[paper](https://arxiv.org/pdf/2308.10901)] [[website](https://human-world-model.github.io)]
- Learning to Act from Actionless Videos through Dense Correspondences **`2023.10`** [[paper](https://arxiv.org/pdf/2310.08576)] [[code](https://github.com/flow-diffusion/AVDC)] [[website](https://flow-diffusion.github.io)]
- HARP: Autoregressive Latent Video Prediction with High-Fidelity Image Generator **`ICIP 2022`** [[paper](https://arxiv.org/pdf/2209.07143)] [[website](https://sites.google.com/view/harp-videos/home)]
- DayDreamer: World Models for Physical Robot Learning **`CoRL 2022`** [[paper](https://arxiv.org/pdf/2206.14176)] [[code](https://github.com/danijar/daydreamer)] [[website](https://danijar.com/project/daydreamer/)]

## World Models

- Genie: Generative Interactive Environments **`arXiv 2024.2`** [[paper](https://arxiv.org/pdf/2402.15391)] [[website](https://sites.google.com/view/genie-2024/)]
- GAIA-1: A Generative World Model for Autonomous Driving **`arXiv 2023.9`** [[paper](https://arxiv.org/pdf/2309.17080)] [[website](https://wayve.ai/thinking/introducing-gaia1/)]
- Masked Autoencoding for Scalable and Generalizable Decision Making **`arXiv 2023.5`** [[paper](https://arxiv.org/pdf/2211.12740)]
- Transformers are Sample-Efficient World Models **`ICLR 2023`** [[paper](https://arxiv.org/pdf/2209.00588)] [[code](https://github.com/eloialonso/iris)]
- Transformer-based World Models Are Happy With 100k Interactions **`ICLR 2023`** [[paper](https://arxiv.org/pdf/2303.07109)] [[code](https://github.com/jrobine/twm)]
- Iso-Dream: Isolating and Leveraging Noncontrollable Visual  Dynamics in World Models **`NeurIPS 2022`** [[paper](https://arxiv.org/pdf/2205.13817)] [[code](https://github.com/panmt/Iso-Dream?tab=readme-ov-file)] [[website](https://sites.google.com/view/iso-dream)]
- Masked World Models for Visual Control **`CoRL 2022`** [[paper](https://arxiv.org/pdf/2206.14244)] [[code](https://github.com/younggyoseo/MWM)] [[website](https://sites.google.com/view/mwm-rl)]
- Dream to control: Learning Behaviors By Latent Imagination **`ICLR 2020`** [[paper](https://arxiv.org/pdf/1912.01603)]

## Other useful Awesome lists

- Awesome World Models for Autonomous Driving [[code](https://github.com/LMD0311/Awesome-World-Model)] 
